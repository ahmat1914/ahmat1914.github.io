---
title: 决策树工作原理示例
date: 2020-04-12 23:25:07
category: 机器学习
tags: 树模型
mathjax: true
---

### 数据

我们从 Zoo 数据集中抽出10条用于展示决策树工作原理。其中 `class`是预测目标特征，属于分类问题。

> Zoo DataSet http://archive.ics.uci.edu/ml/machine-learning-databases/zoo/
> Data Set Information: A simple database containing 17 Boolean-valued attributes. The "type" attribute appears to be the class attribute.

训练数据：

![8ef0c19a815e3bbc419d3c4accd8d2c8.png](/images/dc297d45db6e4832a617654be26defce.png)

测试数据：

![cd2ec2fb4aea1fe7e25a8ddbd60d1274.png](/images/173e521777ac454a941dd303d8b33c14.png)

*特征数据（如 `legs`）中，1表示有，0表示无；目标特征（`class`）中1到7代表不同的动物。*

### 训练过程

> 信息增益计算过程请看 [基于熵的信息增益](../undefined) 和 [基于基尼系数的信息增益](../undefined)）*

- 寻找根节点的决策问题

```
# 计算用每一个特征、每一个值切分数据后的信息增益。挑出信息增益最大的作为最佳决策问题。

legs == 0 ? 0.1562499999999999
legs == 2 ? 0.049107142857142905
legs == 4 ? 0.2062500000000001
legs == 6 ? 0.2895833333333334
tail == 0 ? 0.15625
tail == 1 ? 0.15625
domestic == 0 ? 0.1205357142857143
domestic == 1 ? 0.1205357142857143
catsize == 0 ? 0.2895833333333334
catsize == 1 ? 0.2895833333333334

#最大信息增益是 0.289，对应的决策问题是 catsize == 1 ?。
# 这个问题作为根节点的决策问题
```

- 找到 `catsize == 1 ?` 是最佳决策问题；根据`catsize == 1 ?`切分根节点数据集。

![b380fc1d10b9bb1607b740184151ec29.png](/images/1fc667ccc6cd49cdb33209ea36854672.png)


- 寻找左1节点的决策问题

```
# 计算用每一个特征、每一个值切分数据（剩下）后的信息增益。挑出最大的作为最佳决策问题。

legs == 0 ? 0.31999999999999984
legs == 2 ? 0.019999999999999796
legs == 4 ? 0.11999999999999983
tail == 0 ? 0.019999999999999796
tail == 1 ? 0.019999999999999796
domestic == 0 ? 0.0
catsize == 1 ? 0.0

#最大信息增益是 0.319，对应的决策问题是 legs == 0 ?。
# 这个问题作为左1节点的决策问题
```

- 找到 `legs == 0 ?` 是最佳决策问题；根据 `legs == 0 ?` 切分左1节点数据集。

![532f43a0204a621d263a8550d2f9bfe1.png](/images/6890d83054ad4dbd88c4baabe4b90749.png)

- 寻找左2节点的决策问题

```
# 计算用每一个特征、每一个值切分数据（剩下）后的信息增益。挑出最大的作为最佳决策问题。

legs == 0 ? 0.0
tail == 1 ? 0.0
domestic == 0 ? 0.0
catsize == 1 ? 0.0

#信息增益都是 0，本节点作为叶子节点。
```

![38f0452db09ea415f9b9dc3d31a377d0.png](/images/585ad37dd6044fa89836202613ba3e45.png)

- 寻找左2右节点的决策问题

```
# 计算用每一个特征、每一个值切分数据（剩下）后的信息增益。挑出最大的作为最佳决策问题。

legs == 2 ? 0.0
legs == 4 ? 0.0
tail == 0 ? 0.0
tail == 1 ? 0.0
domestic == 0 ? 0.0
catsize == 1 ? 0.0

#信息增益都是 0，本节点作为叶子节点。
```

![2c3074175823acc5eb004e9b4b8dbe70.png](/images/1691afbc5b8545ee86cfe6def22b3ceb.png)

- 寻找右1节点的决策问题

```
# 计算用每一个特征、每一个值切分数据（剩下）后的信息增益。挑出最大的作为最佳决策问题。

legs == 6 ? 0.0
tail == 0 ? 0.0
domestic == 0 ? 0.1111111111111111
domestic == 1 ? 0.11111111111111105
catsize == 0 ? 0.0

#最大信息增益是 0.11，对应的决策问题是 domestic == 0 ? 或 domestic == 1 ? 。
# 任选1个问题作为右1节点的决策问题
```

- 根据 `domestic == 0 ?` 切分左1节点数据集。

![073b6a5bc6dc3fb4cd8ce8b506d09ae2.png](/images/d65eb5a7051e42159792445a6f8c428e.png)

- 寻找右2左节点的决策问题

```
# 计算用每一个特征、每一个值切分数据（剩下）后的信息增益。挑出最大的作为最佳决策问题。

legs == 6 ? 0.0
tail == 0 ? 0.0
domestic == 0 ? 0.0
catsize == 0 ? 0.0

#信息增益都是 0，本节点作为叶子节点。
```

![283c197506ee8a48e3dfc2c449b9afac.png](/images/94bd57c33f7b4be78ed709c7fc9f49a6.png)

- 寻找右2右节点的决策问题

```
# 计算用每一个特征、每一个值切分数据（剩下）后的信息增益。挑出最大的作为最佳决策问题。

legs == 6 ? 0.0
tail == 0 ? 0.0
domestic == 1 ? 0.0
catsize == 0 ? 0.0

#信息增益都是 0，本节点作为叶子节点。
```

![d07c392dcf12e87351de196fc06d0f46.png](/images/dce9cb6e43564f4d9a531311d651da91.png)


最终训练好的决策树长这样

```
catsize == 1 ?
--> True:
  legs == 0 ?
  --> True:
    Predict {4: 1}
  --> False:
    Predict {1: 4}
--> False:
  domestic == 0 ?
  --> True:
    Predict {7: 1, 6: 1}
  --> False:
    Predict {6: 1}
```

![85646ae39dc34e6d122a7dc54eeb7593.png](/images/f0b135fc10b241b1aa2d6d47fc49d2ac.png)


### 预测过程

##### 测试数据示例1

![8e2e2419edfb5becf1de3692c70ba53c.png](/images/1fd1a69d2dd943b0a575ac0c658c45f9.png)

分流的决策问题序列如下

```
catsize == 1 ?
--> True:
  legs == 0 ?
  --> False:
    Predict {1: 4}

```

预测结果为1，实际分类是2，因此分类错误。


##### 测试数据示例2

![4bc04a6394313e0cb5b742a0d04ff761.png](/images/c2bd6bc81c50411fa9fd1138f71773c8.png)


分流的决策问题序列如下

```
catsize == 1 ?
--> True:
  legs == 0 ?
  --> False:
    Predict {1: 4}
```

预测结果为1，实际分类也是1，因此分类正确。

...
...

测试了 20条测试数据示例，$分类正确数/20=0.76$
