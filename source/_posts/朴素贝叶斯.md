---
title: 朴素贝叶斯
category:
  - MachineLearning
tags:
  - 贝叶斯
  - 概率
mathjax: true
date: 2021-02-24 19:15:02
img: /images/naive.jpg
---

朴素贝叶斯方法是基于贝叶斯定于和特征条件独立假设的分类方法。
<!--more-->

对于给定的训练数据集
1. 首先基于条件独立假设学习输入输出的联合概率分布；
2. 然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出 y。

朴素贝叶斯法优点
* 实现简单
* 学习与预测效率都高

### 基本方法
朴素贝叶斯法国训练数据学习联合概率分布。具体的学习先验概率分布和条件概率分布。

对离散随机变量而言，联合分布概率质量函数为 $Pr(X = x & Y = y)$

$$P(X=x\ and\ Y=y)=P(X=x) * P(Y=y|X=x)=P(Y=y) * P(=X=x|Y=y)$$

计算条件概率分布 P(=X=x|Y=y) 是有困难（有指数级数量的参数）：
* 假设 X 是[m, n]维数据，即训练集有n个特征，每一个是离散型变量，有$S_n$ 种取值；
* Y是[m, 1]维数据，Y 是离散型变量，有 K 种取值；
* 那么参数个数为 $K * \prod_{i=0}^n{S_n}$

于是，朴素贝叶斯对条件概率分布做了条件独立性假设，使用离散型独立变量的联合分布计算公式 $$P(X=x\ and\ Y=y)=P(X=x) * P(Y=y)$$，避免了计算条件概率分布，因此得名朴素。

参考文献
* 《统计学习方法》-李航

